{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Responses API with function call\n",
    "\n",
    "This example demonstrates how to use function calling with OpenAI's Responses API.\n",
    "\n",
    "**Note: Current support for the OpenAI Responses API is limited to `initiate_chat` with a two-agent chat. Future releases will included expanded support for group chat and the `run` interfaces.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install AG2 and dependencies\n",
    "\n",
    "To be able to run this notebook, you will need to install AG2 with the `openai` extra.\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install `ag2` with 'openai' extra:\n",
    "```bash\n",
    "pip install ag2[openai]\n",
    "```\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "# Configure the LLM\n",
    "llm_config = LLMConfig({\n",
    "    \"api_type\": \"responses\",\n",
    "    \"model\": \"gpt-5-nano\",\n",
    "    \"temperature\": 0.2,\n",
    "})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# A simple function we want the assistant to call as a *tool*\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "def add_numbers(a: float, b: float) -> str:\n",
    "    \"\"\"Return the sum of *a* and *b* as a string (for easy printing).\"\"\"\n",
    "    return str(a + b)\n",
    "\n",
    "\n",
    "# Create a *User* agent that will EXECUTE tools.\n",
    "user = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,  # No LLM needed for the executor agent\n",
    "    human_input_mode=\"NEVER\",  # Run fully autonomously for the demo\n",
    ")\n",
    "\n",
    "# Create an *Assistant* agent that will REASON about when to call tools.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    # ⚠️  Ensure you have a valid OPENAI_API_KEY exported in your env.\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Register the tool for both agents:\n",
    "#   • assistant → can *propose* it via a tool call (register_for_llm)\n",
    "#   • user      → will actually *execute* it (register_for_execution)\n",
    "# ------------------------------------------------------------------\n",
    "assistant.register_for_llm(description=\"Add two numbers together.\")(add_numbers)\n",
    "user.register_for_execution()(add_numbers)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Kick-off a short chat. The assistant should recognise that calling the\n",
    "# tool is the best way to fulfil the request and trigger it automatically.\n",
    "# ------------------------------------------------------------------\n",
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"Hi, please add 42 and 58.\",\n",
    "    max_turns=2,\n",
    "    clear_history=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "This notebook demonstrates how to use tool calling with OpenAI's Responses API.",
   "tags": [
    "tool calling",
    "tools",
    "function calling",
    "responses"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
